# -*- coding: utf-8 -*-
"""CÃ³pia de Damos-lhe as boas-vindas ao Colaboratory

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pomAG7cIIuYow2wC1HHHktO5q04Jil0H
"""

import cv2
import numpy as np
from PIL import Image
from google.colab.patches import cv2_imshow

import zipfile
path = '/content/sample_data/yalefaces.zip'
zip_object = zipfile.ZipFile(file=path, mode = 'r')
zip_object.extractall('./')
zip_object.close()

import os
print(os.listdir('/content/yalefaces/train'))

imagem_teste = '/content/yalefaces/train/ra2003.far.jpeg'
imagem = Image.open(imagem_teste).convert('L')

imagem_np = np.array(imagem, 'uint8')
cv2_imshow(imagem_np)
print(imagem_np.shape)

network = cv2.dnn.readNetFromCaffe('/content/sample_data/deploy.prototxt.txt', '/content/sample_data/res10_300x300_ssd_iter_140000.caffemodel')

imagem = cv2.cvtColor(imagem_np, cv2.COLOR_GRAY2BGR)
(h, w) = imagem.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(imagem, (100, 100)), 1.0, (100,100), (104.0, 117.0, 123.0))
network.setInput(blob)
deteccoes = network.forward()

conf_min = 0.7
imagem_cp = imagem.copy()
for i in range(0, deteccoes.shape[2]):
  confianca = deteccoes[0, 0, i, 2]
  if confianca > conf_min:
    bbox = deteccoes[0, 0, i, 3:7] * np.array([w, h, w, h])
    (start_x, start_y, end_x, end_y) = bbox.astype('int')
    roi = imagem_cp[start_y:end_y, start_x:end_x]
    text = "{:.2f}%".format(confianca * 100)
    cv2.putText(imagem, text, (start_x, start_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 2)
    cv2.rectangle(imagem, (start_x, start_y), (end_x, end_y), (0,255,0), 2)
face = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
cv2_imshow(imagem)
print(imagem.shape)
print(text)

face = cv2.resize(face, (60,80))
cv2_imshow(face)
print(face.shape)

def detecta_face(network, path_imagem, conf_min = 0.7):
  imagem = Image.open(path_imagem).convert('L')
  imagem = np.array(imagem, 'uint8')
  imagem = cv2.cvtColor(imagem, cv2.COLOR_GRAY2BGR)
  (h, w) = imagem.shape[:2]
  blob = cv2.dnn.blobFromImage(cv2.resize(imagem, (100, 100)), 1.0, (100,100), (104.0, 117.0, 123.0))
  network.setInput(blob)
  deteccoes = network.forward()

  face = None
  for i in range(0, deteccoes.shape[2]):
    confianca = deteccoes[0, 0, i, 2]
    if confianca > conf_min:
      bbox = deteccoes[0, 0, i, 3:7] * np.array([w, h, w, h])
      (start_x, start_y, end_x, end_y) = bbox.astype('int')
      roi = imagem[start_y:end_y, start_x:end_x]
      roi = cv2.resize(roi, (60,80))
      cv2.rectangle(imagem, (start_x, start_y), (end_x, end_y), (0,255,0), 2)
      face = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
  return face, imagem

teste_imagem = '/content/yalefaces/train/ra2003.left.jpeg'
face, imagem = detecta_face(network, teste_imagem)
cv2_imshow(imagem)
cv2_imshow(face)

def get_image_data():
  paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]
  #print(paths)
  faces = []
  ids = []
  for path in paths:
    if path == "/content/yalefaces/train/.ipynb_checkpoints":
      continue
    face, imagem = detecta_face(network, path)
    #cv2_imshow(imagem)
    #cv2_imshow(face)
    path
    id = int(os.path.split(path)[1].split('.')[0].replace('subject', '').replace('ra', ''))
    id
    ids.append(id)
    faces.append(face)
    cv2_imshow(face)
  return np.array(ids), faces

ids, faces = get_image_data()

"""# Eigen

"""

eigen_classifier = cv2.face.EigenFaceRecognizer_create()
eigen_classifier.train(faces, ids)
eigen_classifier.write('/content/eigen_classifier.yml')

eigen_classifier = cv2.face.EigenFaceRecognizer_create()
eigen_classifier.read('/content/sample_data/eigen_classifier.yml')

imagem_teste = '/content/yalefaces/test/ra2003.happy.jpeg'
face, imagem = detecta_face(network, imagem_teste)
face, face.shape

previsao = eigen_classifier.predict(face)
previsao

import re

re.findall

saida_esperada = int(os.path.split(imagem_teste)[1].split('.')[0].replace('subject', '').replace('ra', ''))

saida_esperada

cv2.putText(imagem, 'Pred: ' + str(previsao[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0,255,0))
cv2.putText(imagem, 'Exp: ' + str(saida_esperada), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0,255,0))
cv2_imshow(imagem)

def teste_reconhecimento(imagem_teste, classificador, show_conf = False):
  face, imagem_np = detecta_face(network, imagem_teste)
  previsao, conf = classificador.predict(face)
  saida_esperada = int(os.path.split(imagem_teste)[1].split('.')[0].replace('subject', '').replace('ra', ''))
  cv2.putText(imagem_np, 'Pred: ' + str(previsao), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0,255,0))
  cv2.putText(imagem_np, 'Exp: ' + str(saida_esperada), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0,255,0))
  if show_conf:
    print(conf)

  return imagem_np, previsao

imagem_np, previsao = teste_reconhecimento(imagem_teste, eigen_classifier, True)
cv2_imshow(imagem_np)

"""# Fisher

""
fisher_classifier = cv2.face.FisherFaceRecognizer_create()
fisher_classifier.train(faces, ids)
fisher_classifier.write('fisher_classifier.yml')

fisher_classifier = cv2.face.FisherFaceRecognizer_create()
fisher_classifier.read('/content/fisher_classifier.yml')

imagem_teste = '/content/yalefaces/test/ra2003.happy.jpeg'
imagem_np, previsao = teste_reconhecimento(imagem_teste, fisher_classifier, True)
cv2_imshow(imagem_np)

"""# LBPH


"""

lbph_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_classifier.train(faces, ids)
lbph_classifier.write('lbph_classifier.yml')

lbph_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_classifier.read('/content/lbph_classifier.yml')

imagem_teste = '/content/yalefaces/test/ra2003.happy.jpeg'
imagem_np, previsao = teste_reconhecimento(imagem_teste, lbph_classifier, True)
cv2_imshow(imagem_np)
